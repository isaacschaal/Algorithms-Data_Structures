{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1: Introduction\n",
    "=======\n",
    "\n",
    "When prompted with the LBA, I knew already where I wanted to navigate. I currently reside in Hyderabad, India, specifcially in HITEC City, an up an coming IT and Tech hub on the edge of the city. However, the more interesting cultural areas of the city are near the center. Specifically, I wanted to go the Old City, the historic Muslim part of the city. However, before I wanted to go there, I wanted to learn a little bit more about the Old City. I opened up my browser and went to wikipedia...and then stopped. In spirit of the assignment, I was curious if instead of autonomosly navigating from HITEC City to the Old City, I autonomously navigated from the _wikipedia page_ of HITEC City to the _wikipedia page_ of the Old City. I found this challenge engaging, and set to work.\n",
    "\n",
    "\n",
    "Section 2: Wikipedia Python Package\n",
    "=======\n",
    "\n",
    "My first step was to figure out how to communicate with Wikipedia from Python. I knew that I could possibly scrape manually from each wikipedia page, but I guessed that there was an easier way. Luckily, the wikipedia API has already been integrated into a Python package, https://wikipedia.readthedocs.io/en/latest/code.html#api.\n",
    "\n",
    "This package allows lots of useful functionality.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Africa\n",
      "South Africa, officially the Republic of South Africa (RSA), is the southernmost country in Africa. \n",
      "['+27', '.za', '10th BRICS summit', '11th BRICS summit', '16th meridian east']\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "#Save a wikipedia page as a wiki object\n",
    "SA = wikipedia.page(\"South Africa\")\n",
    "# Return the title of the page\n",
    "print (SA.title)\n",
    "# Return the summary of the page (this call just the first 100 characters)\n",
    "print (SA.summary[:100])\n",
    "# Return the links on the page  (this call just the first 5)\n",
    "print (SA.links[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was exactly the functionality that I needed. \n",
    "The next step was to determine the rules.\n",
    "\n",
    "Section 3: Rules - Wikirace\n",
    "=======\n",
    "\n",
    "I decided to do this in the style of a wikirace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikiracing is a game using the online encyclopedia Wikipedia which focuses on traversing links from one page to another. It has many different variations and names, including The Wikipedia Game, Wikipedia Maze, Wikispeedia, Wikiwars, Wikipedia Ball, and Litner Ball. External websites have been created to facilitate the game.\n",
      "The Seattle Times has recommended it as a good educational pastime for children and the Larchmont Gazette has said, \"While I don't know any teenagers who would curl up with an encyclopedia for a good read, I hear that a lot are reading it in the process of playing the Wikipedia Game\".\n",
      "The Amazing Wiki Race has been an event at the TechOlympics and the Yale Freshman Olympics.\n",
      "The average number of links separating any Wikipedia page from the United Kingdom page is 3.67. Other common houserules such as not using the United States page increase the difficulty of the game.\n"
     ]
    }
   ],
   "source": [
    "wikirace = wikipedia.page('wikirace')\n",
    "print (wikirace.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read about the wikiracing (and have done it it the past) and so decided on a set of rules.\n",
    "\n",
    "1. I must start on the wikipedia page that I am starting from, this will be called start\n",
    "2. I must end on the wikepedia paget that I am looking for, this will be called goal.\n",
    "3. I can only navigate by using the hyperlinks on a the current wikipedia page. I can choose any of the links using any selection procedure I want, but the limit is that I can only use the name and order of the links. \n",
    "4. Once I choose a link, I can not use the back button. I must continue from that page.\n",
    "\n",
    "This can be broken down into two algorithms, a navigation algorithm and an execution algorithim.\n",
    "The navigation algorithm will, given a list of links on a wikipedia page, choose which link to go to.\n",
    "The execution algorithm will, given a link, check if the given link is the goal, and if not navigate to the next page and return a list of all links on that page.\n",
    "\n",
    "My overall algorithm will be recursive. I will first call a driver function which calls the execution algorithm for the first time. Each call of the execution algorithm will check if the given link is the goal, if not it will call the navigation algorithm, and then recursively call itself (the execution algorithm) again. \n",
    "\n",
    "This encompasses the essense of a greedy algorithm, as at each step, the navigation algorithm chooses the locally optimal next link. It does not look ahead at the choices, but instead chooses the next link based on a specific metric.\n",
    "\n",
    "Section 4: First Attempt\n",
    "=======\n",
    "\n",
    "My first attempt at creating an algorithm was in real life and not in python.\n",
    "My execution algorithm was simple, as I would just click on the link.\n",
    "My navigation algorithm for this first attempt was simple:   \n",
    "First, check if the desired link is on the page.  \n",
    "If so, click it and be done.  \n",
    "If not, choose the first link on the page.\n",
    "\n",
    "This is a simple algorithm that I can execute manually, and as such, I don't think it will be very succesful.\n",
    "I tried this algorithm,   starting from \n",
    "HITEC City : https://en.wikipedia.org/wiki/HITEC_City   \n",
    "with the goal of the Old City : https://en.wikipedia.org/wiki/Old_City_(Hyderabad,_India)\n",
    "\n",
    "The images from my first manual implementation of this algorithm are located in an attached folder.\n",
    "\n",
    "After 16 steps, and with little success, I decided that I needed to iterate. While I learned some interesting things about computing, I wasn't getting any closer to learning about the Old City.\n",
    "\n",
    "Section 5: Second Attempt\n",
    "=======\n",
    "\n",
    "The first thing I updated was my execution algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the driver algorithm,that starts the process\n",
    "# The input is a start and goal, both string.\n",
    "def wiki(start, goal, navigation):\n",
    "    # It creates an array that stores the path of the algorithm\n",
    "    link_array = [start]\n",
    "    # The counter is used to stop the algorithm after a certain\n",
    "    # number of steps\n",
    "    counter = 0\n",
    "    # Call the execution algorithm\n",
    "    execution(link_array, goal, counter, navigation)\n",
    "    # Return the path\n",
    "    print (link_array)\n",
    "\n",
    "def execution(link_array, goal, counter, navigation):\n",
    "    #This is how we exit recursion\n",
    "    if link_array[-1] == goal:\n",
    "        print( \"Success\")\n",
    "        return link_array\n",
    "    \n",
    "    #If not, we find all links from the page we have navigated to\n",
    "    base = wikipedia.page(link_array[-1])\n",
    "    new_links = base.links\n",
    "    # Choose the next link by calling the navigation algorithm\n",
    "    next_step = navigation(link_array, goal, counter, new_links)\n",
    "    link_array.append(next_step)\n",
    "    #Update the counter\n",
    "    counter+=1\n",
    "    if counter < 20:\n",
    "        # Call the execution function recursively, \n",
    "        # if the counter is below the specified amount\n",
    "        execution(link_array, goal, counter, navigation)\n",
    "    else: \n",
    "        print (\"Failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This execution algorthim looked good! However, I still needed to create a navigation algorithm. Given the rules, I knew I was allowed to use the order and names of all links on a page in order to choose a link. The order didn't seem to be a very helpful metric on my first attempt, which confirms my suspicion that it would not be very helpful for navigation. Thus, I am left with the names of the links. I decided that similarity between the name of each link and the goal would be a good metric. However, I still needed to find a way to calculate this. I did some research, and came across the Largest Common Subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest common subsequence (LCS) problem is the problem of finding the longest subsequence common to all sequences in a set of sequences (often just two sequences). It differs from the longest common substring problem: unlike substrings, subsequences are not required to occupy consecutive positions within the original sequences. The longest common subsequence problem is a classic computer science problem, the basis of data comparison programs such as the diff utility, and has applications in bioinformatics. It is also widely used by revision control systems such as Git for reconciling multiple changes made to a revision-controlled collection of files.\n"
     ]
    }
   ],
   "source": [
    "LargestCommonSubsequence = wikipedia.page('Largest Common Subsequence')\n",
    "print (LargestCommonSubsequence.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seemed like what I needed. It was more robust that the longest common string, as there might be similarities between strings that were not neccesarily in order. However, there was a problem. I did research on how to solve this problem, but the first algorithm that I came across was not ideal. It got the correct answer, but did so in O(2^n) time. This was unacceptable. Luckily, this problem has been solved, using a concept known as dynamic programming. The essence of dynamix programming is that it helps to solve a problem which can be broken up into many subproblems. Importantly, solving one subproblem can be done with the answers of other subproblems. Thus, in a naive approach, the same problem is being solved many times. Dynamic programming records the solution of this subproblem, and uses it instead of solving the problem again next time it is asked. Our solution can thus be implemented in O(mn), with m and n being the lenghts of the two strings being compared. This is a dramatically faster solution.\n",
    "\n",
    "The following code was found from https://www.geeksforgeeks.org/longest-common-subsequence/.  I edited the output slightly (line 47) to return the LCS in a format that worked better for my uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic programming implementation of LCS problem\n",
    " \n",
    "# Returns length of LCS for X[0..m-1], Y[0..n-1] \n",
    "def lcs(X, Y, m, n):\n",
    "    L = [[0 for x in range(n+1)] for x in range(m+1)]\n",
    " \n",
    "    # Following steps build L[m+1][n+1] in bottom up fashion. Note\n",
    "    # that L[i][j] contains length of LCS of X[0..i-1] and Y[0..j-1] \n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0 or j == 0:\n",
    "                L[i][j] = 0\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1] + 1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    " \n",
    "    # Following code is used to print LCS\n",
    "    index = L[m][n]\n",
    " \n",
    "    # Create a character array to store the lcs string\n",
    "    lcs = [\"\"] * (index+1)\n",
    "    lcs[index] = \"\\0\"\n",
    " \n",
    "    # Start from the right-most-bottom-most corner and\n",
    "    # one by one store characters in lcs[]\n",
    "    i = m\n",
    "    j = n\n",
    "    while i > 0 and j > 0:\n",
    " \n",
    "        # If current character in X[] and Y are same, then\n",
    "        # current character is part of LCS\n",
    "        if X[i-1] == Y[j-1]:\n",
    "            lcs[index-1] = X[i-1]\n",
    "            i-=1\n",
    "            j-=1\n",
    "            index-=1\n",
    " \n",
    "        # If not same, then find the larger of two and\n",
    "        # go in the direction of larger value\n",
    "        elif L[i-1][j] > L[i][j-1]:\n",
    "            i-=1\n",
    "        else:\n",
    "            j-=1\n",
    "            \n",
    "    ###I edited the below line to output in my prefered format\n",
    "    return (\"\".join(lcs[:-1]) )\n",
    " \n",
    "# Driver program\n",
    "\n",
    "def LCS(string1, string2):\n",
    "    X = string1\n",
    "    Y = string2\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    return (lcs(X, Y, m, n))\n",
    "\n",
    "    \n",
    "# This code is contributed by BHAVYA JAIN from Geeks_for_Geeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ie'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the LCS\n",
    "LCS(\"nice\", 'pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I had a way to calculate the metric. I just needed to implement it into my navigation algorithm. My first idea was to find the score for each link using LCS, then use the max function to find the maximum value. However, the problem was that there might be multiple links that have the same score. I decided that in this situation, I wanted to choose the link that was the shortest, meaning that the LCS would compromise the most percentage of the link as a whole, which would be more likely to be an acutal connection between the goal and that link. This is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigation1(link_array, goal, counter, new_links):\n",
    "\n",
    "    link_scores = []\n",
    "    print (link_array[-1])\n",
    "    for link in new_links:\n",
    "        link_scores.append((len(LCS(link, goal)),LCS(link, goal),link))\n",
    "    \n",
    "    # Find the max score of all the link scores\n",
    "    mx = max(link_scores, key=lambda x: x[0])[0]\n",
    "    \n",
    "    max_scores = []\n",
    "    #find all links that have score = mx\n",
    "    for score in link_scores:\n",
    "        if score[0] == mx:\n",
    "            max_scores.append(score)\n",
    "\n",
    "    #Find the link in max_scores that has the shortest link title\n",
    "    mn =(min(max_scores, key=lambda x: len(x[2])))\n",
    "   \n",
    "    #Return the name of the link\n",
    "    return mn[2]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITEC City\n",
      "List of educational institutions in Hyderabad (India)\n",
      "Central Institute for Medicinal and Aromatic Plants (Hyderabad, India)\n",
      "Council of Scientific and Industrial Research\n",
      "Hyderabad, India\n",
      "Success\n",
      "['HITEC City', 'List of educational institutions in Hyderabad (India)', 'Central Institute for Medicinal and Aromatic Plants (Hyderabad, India)', 'Council of Scientific and Industrial Research', 'Hyderabad, India', 'Old City (Hyderabad, India)']\n"
     ]
    }
   ],
   "source": [
    "# This is the first test of the algorithm.\n",
    "# Note that the start and goal must be the exact name\n",
    "# of the page on wikipedia\n",
    "wiki('HITEC City','Old City (Hyderabad, India)', navigation1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! My algorithm correctly navigated from HITEC City to the Old City. I am now finally able to read all the information about the Old City to gain a deeper cultural understanding before going there.\n",
    "\n",
    "However, I wanted to see how good my algorithim really was. I decided to test it with a different case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydrogen\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Indium halides\n",
      "Indium\n",
      "Failure\n",
      "['Hydrogen', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides', 'Indium', 'Indium halides']\n"
     ]
    }
   ],
   "source": [
    "#I decided to test if my algorithim could navigate from \n",
    "# \"Hydrogen\" to \"India,\" two unrelated words.\n",
    "\n",
    "wiki('Hydrogen', 'India', navigation1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there is a problem. My algorithim got stuck in an infinite loop. At each decision point, the optimal link was one that the algorithm had visited before. Because the algorithim is deterministic and teh same input will produce the same output, once it returns to something it has visited before, it will be stuck in a loop, because it will just continue on the path from the position it returned to, and run into the same problem again. This is an infinite loop. In the next section, I will fix this.\n",
    "\n",
    "Section 6: Third Attempt\n",
    "=======\n",
    "\n",
    "In order to prevent an infinite loop, I needed to update the navigation function so that it will not choose a link  that it has already seen. I implement this in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigation2(link_array, goal, counter,new_links):\n",
    "\n",
    "    link_scores = []\n",
    "    print (link_array[-1])\n",
    "    for link in new_links:\n",
    "        link_scores.append((len(LCS(link, goal)),LCS(link, goal),link))\n",
    "    \n",
    "    # Find the max score of all the link scores\n",
    "    mx = max(link_scores, key=lambda x: x[0])[0]\n",
    "    \n",
    "    #Make a list of all links that have score = mx\n",
    "    # However, they also must not be links we have previously \n",
    "    # visited.\n",
    "    no_repeats = False\n",
    "    while not no_repeats:\n",
    "        max_scores = []\n",
    "        #find all links that have score = mx\n",
    "        for score in link_scores:\n",
    "            if score[0] == mx:\n",
    "                max_scores.append(score)\n",
    "        #Now delete all links that have been used before\n",
    "        deletion_list = [False for x in range(len(max_scores))]\n",
    "        for i in range(len(max_scores)):\n",
    "            for j in range(len(link_array)):\n",
    "                if max_scores[i][2] == link_array[j]:\n",
    "                    deletion_list[i] = True\n",
    "        # Delete in reversed order so indexing doesn't become a problem\n",
    "        for i in reversed(range(len(deletion_list))):\n",
    "            if deletion_list[i] == True:\n",
    "                del max_scores[i]\n",
    "                \n",
    "        #If we have at least one new link at this score\n",
    "        # If not, decrease mx and repeat\n",
    "        if len(max_scores) > 0:\n",
    "            no_repeats = True\n",
    "        else:\n",
    "            mx -=1\n",
    "        \n",
    "    #Find the link in max_scores that has the shortest link title\n",
    "    mn =(min(max_scores, key=lambda x: len(x[2])))\n",
    "   \n",
    "    #Return the name of the link\n",
    "    return mn[2]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITEC City\n",
      "List of educational institutions in Hyderabad (India)\n",
      "Central Institute for Medicinal and Aromatic Plants (Hyderabad, India)\n",
      "Council of Scientific and Industrial Research\n",
      "Hyderabad, India\n",
      "Success\n",
      "['HITEC City', 'List of educational institutions in Hyderabad (India)', 'Central Institute for Medicinal and Aromatic Plants (Hyderabad, India)', 'Council of Scientific and Industrial Research', 'Hyderabad, India', 'Old City (Hyderabad, India)']\n"
     ]
    }
   ],
   "source": [
    "wiki( 'HITEC City', 'Old City (Hyderabad, India)', navigation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydrogen\n",
      "Indium\n",
      "Indium halides\n",
      "Indium trichloride\n",
      "Indigane\n",
      "Silk in the Indian subcontinent\n",
      "South India\n",
      "East India\n",
      "Success\n",
      "['Hydrogen', 'Indium', 'Indium halides', 'Indium trichloride', 'Indigane', 'Silk in the Indian subcontinent', 'South India', 'East India', 'India']\n"
     ]
    }
   ],
   "source": [
    "wiki('Hydrogen', 'India', navigation2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This updated navigation algorithm suceeded on both our initial goal, and on our new test case. We can try more test cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston\n",
      "Indiana\n",
      "Indiana Day\n",
      "Indiana Code\n",
      "Indianapolis\n",
      "Success\n",
      "['Boston', 'Indiana', 'Indiana Day', 'Indiana Code', 'Indianapolis', 'India']\n",
      "Xylophone\n",
      "Encyclopædia Britannica Eleventh Edition\n",
      "Encyclopædia Britannica Ninth Edition\n",
      "Egyptian hieroglyphs\n",
      "Egyptian Grammar: Being an Introduction to the Study of Hieroglyphs\n",
      "Egyptian language\n",
      "Ancient Egyptian funerary practices\n",
      "Ancient Egyptian mathematics\n",
      "Egyptian fractions\n",
      "Egyptian mathematics\n",
      "List of ancient Egyptian papyri\n",
      "Elephantine papyri\n",
      "Ancient Egyptian religion\n",
      "Ancient Egyptian burial customs\n",
      "List of ancient Egyptian dynasties\n",
      "Ancient Egyptian trade\n",
      "Ancient Egyptian philosophy\n",
      "Ancient Egyptian funerary texts\n",
      "Pyramid Texts\n",
      "Success\n",
      "['Xylophone', 'Encyclopædia Britannica Eleventh Edition', 'Encyclopædia Britannica Ninth Edition', 'Egyptian hieroglyphs', 'Egyptian Grammar: Being an Introduction to the Study of Hieroglyphs', 'Egyptian language', 'Ancient Egyptian funerary practices', 'Ancient Egyptian mathematics', 'Egyptian fractions', 'Egyptian mathematics', 'List of ancient Egyptian papyri', 'Elephantine papyri', 'Ancient Egyptian religion', 'Ancient Egyptian burial customs', 'List of ancient Egyptian dynasties', 'Ancient Egyptian trade', 'Ancient Egyptian philosophy', 'Ancient Egyptian funerary texts', 'Pyramid Texts', 'Egyptian pyramids']\n"
     ]
    }
   ],
   "source": [
    "wiki ( 'Boston', 'India', navigation2)\n",
    "\n",
    "wiki ( 'Xylophone','Egyptian pyramids',navigation2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are looking pretty good. However, we can still find test cases where it will fail. The below two cells show two different examples of failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egyptian pyramids\n",
      "Pyramid of Elephantine\n",
      "Geographic coordinate system\n",
      "Selenographic coordinates\n",
      "Full Moon\n",
      "Planetary objects proposed in religion, astrology, ufology and pseudoscience\n",
      "Val Johnson incident\n",
      "Kelly–Hopkinsville encounter\n",
      "1566 celestial phenomenon over Basel\n",
      "Climatology\n",
      "Atmospheric boundary layer\n",
      "Atmospheric Model Intercomparison Project\n",
      "Coupled model intercomparison project\n",
      "Navy Operational Global Atmospheric Prediction System\n",
      "Navy Global Environmental Model\n",
      "Regional Atmospheric Modeling System\n",
      "Mars regional atmospheric modeling system\n",
      "Mars Exploration Rovers\n",
      "Multi-Mission Radioisotope Thermoelectric Generator\n",
      "Neutron capture therapy of cancer\n",
      "Failure\n",
      "['Egyptian pyramids', 'Pyramid of Elephantine', 'Geographic coordinate system', 'Selenographic coordinates', 'Full Moon', 'Planetary objects proposed in religion, astrology, ufology and pseudoscience', 'Val Johnson incident', 'Kelly–Hopkinsville encounter', '1566 celestial phenomenon over Basel', 'Climatology', 'Atmospheric boundary layer', 'Atmospheric Model Intercomparison Project', 'Coupled model intercomparison project', 'Navy Operational Global Atmospheric Prediction System', 'Navy Global Environmental Model', 'Regional Atmospheric Modeling System', 'Mars regional atmospheric modeling system', 'Mars Exploration Rovers', 'Multi-Mission Radioisotope Thermoelectric Generator', 'Neutron capture therapy of cancer', 'Radioisotope thermoelectric generator']\n"
     ]
    }
   ],
   "source": [
    "wiki ( 'Egyptian pyramids','Xylophone',navigation2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlanta\n",
      "Montego Bay\n",
      "Bog Walk\n",
      "Hodges, Jamaica\n",
      "Broughton, Jamaica\n",
      "Stonehenge, Jamaica\n",
      "Roxborough, Manchester\n",
      "Roaring River Park\n",
      "Rose Hall, Montego Bay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Isaac/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/Isaac/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "ename": "DisambiguationError",
     "evalue": "\"Rose Hall\" may refer to: \nRose Hall, New York City\nRose Hall, Guyana\nRose Hall, Saint Vincent and the Grenadines\nRose Hall, Oxford\nRose Hall, Montego Bay\nRose Hall Beach",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDisambiguationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-2d88ac292410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwiki\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Atlanta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yoga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mwiki\u001b[0;34m(start, goal, navigation)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Call the execution algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Return the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the execution function recursively,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# if the counter is below the specified amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mexecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnavigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-0699079abe15>\u001b[0m in \u001b[0;36mexecution\u001b[0;34m(link_array, goal, counter, navigation)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#If not, we find all links from the page we have navigated to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mnew_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Choose the next link by calling the navigation algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36mpage\u001b[0;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# if there is no suggestion or search results, the page doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpageid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either a title or a pageid must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self, redirect, preload)\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0mmay_refer_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mli\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_lis\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisambiguationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmay_refer_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDisambiguationError\u001b[0m: \"Rose Hall\" may refer to: \nRose Hall, New York City\nRose Hall, Guyana\nRose Hall, Saint Vincent and the Grenadines\nRose Hall, Oxford\nRose Hall, Montego Bay\nRose Hall Beach"
     ]
    }
   ],
   "source": [
    "wiki( 'Atlanta', 'Yoga', navigation2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the first case, the problem was that our metric was not working to get us closer to the goal. We travelled to niche wikipedia pages about space travel, which are hard to get to Xylophone from. We could try and let our algorithm run longer, but I doubt that this would help. Instead, we would need to find a better metric for searching.  \n",
    "\n",
    "The next case however, was a problem with the wikipedia python package. The name of the link must be specific, or a disambiguation error is thrown, as it is unclear which page should be chosen. Ideally, the \"link\" attribute of each wiki object will be the specific name of the wikipedia page. However, in certain cases, the Python package will communicate with the wikipedia API, but return the name of the link as different from the full name of the page. In this scenario, if our algorithim chooses this page, an error will be thrown. In order to resolve this, either a random page from the possible pages from the unspecific name input could be chosen, or we would need to communicate with the wikipedia API ourselves and circumvent the wikipedia package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 7: Future Work\n",
    "=======\n",
    "\n",
    "I learned several things from working through this assingment. The first was about preventing infinite loops. In an online algorithm like mine, it is possible to prevent infinite loops with a simple check of previous input. However, in real life, infinite loops may occur from external input that cannot so easily be checked. More advanced methods of stopping them must be implemented.\n",
    "\n",
    "Secondly, the greedy nature of our algorithim is limiting. If we \"looked ahead\", we could potentially navigate through wikipedia even faster. For example, our algorithim could look through the links on the pages of all the links that achieve close to max LCS score on a page. Of these links, we would choose the link whose subsequent links have the highest average (or maximum, median, etc.) score. This could improve our search, but would no longer be a greedy algorithm, which is focused only on the local maximum.\n",
    "\n",
    "An interesting question posed by this assignment is the state of the wikipedia network. Wikipedia could easily be represented as a network, with pages corresponding to nodes and hyperlinks between them corresponding to directed edges. Armed with this, many interesting things could be done. A shortest path algorithm could be used on the network to find the optimal way to travel between wikipedia pages. We could also examine certain topics or pages to understand network conectivity, or the entire network as a whole. Due to the large size of the network, powerful computers would need to be used. Interesting analysis could be done, along the lines of which scientific fields are most densly connected, or similar analysis with actors or celebrities.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
