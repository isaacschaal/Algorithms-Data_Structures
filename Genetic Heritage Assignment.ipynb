{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Heritage\n",
    "\n",
    "For this assignment, we are given the following strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings =  [(0,'TTCTACGGGGGGAGACCTTTACGAATCACACCGGTCTTCTTTGTTCTAGCCGCTCTTTTTCATCAGTTGCAGCTAGTGCATAATTGCTCACAAACGTATC'),\n",
    "            (1,'TCTACGGGGGGCGTCATTACGGAATCCACACAGGTCGTTATGTTCATCTGTCTCTTTTCACAGTTGCGGCTTGTGCATAATGCTCACGAACGTATC'),\n",
    "            (2,'TCTACGGGGGGCGTCTATTACGTCGCCAACAGGTCGTATGTTCATTGTCATCATTTTCATAGTTGCGGCCTGTGCGTGCTTACGAACGTATTCC'),\n",
    "            (3,'TCCTAACGGGTAGTGTCATACGGAATCGACACGAGGTCGTATCTTCAATTGTCTCTTCACAGTTGCGGCTGTCCATAAACGCGTCCCGAACGTTATG'),\n",
    "            (4,'TATCAGTAGGGCATACTTGTACGACATTCCCCGGATAGCCACTTTTTTCCTACCCGTCTCTTTTTCTGACCCGTTCCAGCTGATAAGTCTGATGACTC'),\n",
    "            (5,'TAATCTATAGCATACTTTACGAACTACCCCGGTCCACGTTTTTCCTCGTCTTCTTTCGCTCGATAGCCATGGTAACTTCTACAAAGTTC'),\n",
    "            (6,'TATCATAGGGCATACTTTTACGAACTCCCCGGTGCACTTTTTTCCTACCGCTCTTTTTCGACTCGTTGCAGCCATGATAACTGCTACAAACTTC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "These were generated by taking one existing string, and applying some number of transformations (switching, adding, or deleting a character), each done with a low probability. One string was the base, with which two children were created (using transformations). Each of these two children then had two children. We are left with seven strings, but we don't know the lineage. Our task is to find the lineage of these strings. We know that the changes are unlikely, and thus the lineage with the least changes overall (amongst all parents and children) is the most likely lineage.\n",
    "\n",
    "Before we begin our analysis, we will more explicitly review the given information about the strings. We know several things about the strings. Firstly, there are 7 strings, one grandparent, 2 children, and 4 grandchildren. Secondly, the possible operations are inserting a new charecter, deleting an existing charecter, and changing a character. The first metric we will examine them on is LCS, or longest common subsequence.\n",
    "\n",
    "If we have our initial string : TTCTACGGGG\n",
    "and we insert a new character anywhere in the string : TTCTACGGGG\n",
    "the LCS will be the length of the first string.\n",
    "\n",
    "If we have our initial string : TTCTACGGGG\n",
    "and we delete an existing character anywhere in the string : TTCTACGGG\n",
    "the LCS will be the length of the second string.\n",
    "\n",
    "If we have our initial string : TTCTACGGGGG\n",
    "and we change a character anywhere in our string: GTCTACGGGGG\n",
    "the LCS will be the lenght of either string -1. \n",
    "\n",
    "Adding and deleting a character functions similary to changing a character, as the LCS will decrease by 1 but the length of the second string is the same as the original. This complicated matters, as we don't know which operation actually caused the change we see.\n",
    "\n",
    "Thus, we will find the minium number of operations possible to make the difference. We will assume that every change we see is the simplest form of the change, meaning that if we see an additional T, we assume that it was added as a T, and not added as G, deleted, added as C, changed to A, then changed to T. Thus, each difference we see will be counted as 1 modification. This assumption may not be entirely accurate, as some changes most likely were not the simplest. However, we assume that the actual amount of changes of each string is proportional to the minimum possible, that is, if the difference between two strings is a minimum of 10 operations and another two strings is a minimum of 20 operations, we assume that there were roughly twice as many overall operations in the second set of strings. Finding the minimum number of changes possible gives us a consistent and objective metric to compare different family trees.\n",
    "\n",
    "## LCS\n",
    "\n",
    "We must first calculate the LCS between all combinations of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lcs(X , Y):\n",
    "    # get the string lenghts and create an array\n",
    "    m,n = len(X),len(Y)\n",
    "    array = [[None]*(n+1) for i in range(m+1)]\n",
    "     \n",
    "    #iterate through all positions in array\n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            # if either is 0, the LCS is 0\n",
    "            if i == 0 or j == 0 :\n",
    "                array[i][j] = 0\n",
    "            # if the added character is the same, the LCS is +1 \n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                array[i][j] = array[i-1][j-1]+1\n",
    "            # if not, the LCS is the max of the array 1 to the left and 1 above\n",
    "            else:\n",
    "                array[i][j] = max(array[i-1][j] , array[i][j-1])\n",
    "    return array[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCS\n",
      "     0   1   2   3   4   5   6\n",
      "0  100  82  73  72  72  70  80\n",
      "1   82  96  83  81  67  65  70\n",
      "2   73  83  94  73  62  61  67\n",
      "3   72  81  73  97  62  60  63\n",
      "4   72  67  62  62  98  71  82\n",
      "5   70  65  61  60  71  89  79\n",
      "6   80  70  67  63  82  79  94\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "num = len(strings)\n",
    "\n",
    "lengths = pd.DataFrame(np.array([[None for i in range(num)]for j in range(num)]))\n",
    "for col in range(num):\n",
    "    for row in range(num):\n",
    "        lengths[col][row] = lcs(strings[col][1],strings[row][1])\n",
    "print (\"LCS\")\n",
    "print (lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore two strings and see what the LCS (and their lenghts) tells us. If we take string_0 and string_1, we know that the length of string_0 is 100 and the length of string_1 is 96. The LCS between the two is 82. If string_0 was the parent, we know that there must have been at least 4 deletions. Secondly, we know that there must have been 14 changed characters. Thus, at minimum there must have been 18 operations. If string_1 was the parent, we know that there must have been at least 4 additions, and that there must have been 14 changed characters, which again tells us 18 operations. Thus, the minimum number of changes needed if string_0 and string_1 had a direct relationship (regardless of parentage) is `max(len(string_0), len(string_0)) - LCS(string_0, string_1)`.\n",
    "\n",
    "## Minimum Changes\n",
    "\n",
    "This allows us to create a new table, which has the minimum number of changes between each combination of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minimum Changes\n",
      "    0   1   2   3   4   5   6\n",
      "0   0  18  27  28  28  30  20\n",
      "1  18   0  13  16  31  31  26\n",
      "2  27  13   0  24  36  33  27\n",
      "3  28  16  24   0  36  37  34\n",
      "4  28  31  36  36   0  27  16\n",
      "5  30  31  33  37  27   0  15\n",
      "6  20  26  27  34  16  15   0\n"
     ]
    }
   ],
   "source": [
    "min_changes = copy.deepcopy(lengths)\n",
    "for col in range(num):\n",
    "    for row in range(num):\n",
    "        min_changes[col][row] = max(lengths[col][col],lengths[row][row]) - lengths[col][row]\n",
    "print (\"\\nMinimum Changes\")\n",
    "print (min_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a metric for assesing the position of two strings. This metric can be extended to family trees. A given family tree will have minimum number of changes for each relationship, and the sum of all of these will be the minimum number of changes for the entire family tree. We assume that these changes are unlikely, and thus the tree with the lowest minimum number of changes is the most likely to occur.\n",
    "\n",
    "We can now examine this table in order to guess what the correct lineage should be. The first thing to look at is the lowest numbers, which indicate the most likely relationships.\n",
    "\n",
    "We see that (0-1) has 18 changes, (0-6) has 20 changes, (1-2) has 13 changes, (1-3) has 16 changes, (4-6) has 16 changes and (5-6) has 15 changes.  These are all of the relationships with minimum changes of 20 or less, while other relationships have 24-37 changes. From this initial info, it is natural to conclude, that 0 is the grandfather with children 1 and 6, 1 has children 2 and 3, and 6 has children 4 and 5. All of the most likely relationships are included, and so we can confidently say that this is the most likely lineage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of Mistake\n",
    "\n",
    "We are now tasked with estimating the probability of insertions, deletions, and mutations. We can first make the assumption that for each character in the string, there is a small likihood of one of the three transformations. It is unclear if this is the actual process, but it makes sense given the information we have. We can define the probability of a single transformation as $P$. For a given string, the probability of making k mistakes, given n characters is $P_{k-mistakes} = \\binom{n}{k} P^ k(1-P)^{n-k} $. \n",
    "\n",
    "Using a large set of data, we could get empirical estimates of $P_{k-mistakes}$ for given k values. We could then solve for $P$. We could first start by knowing a specific probability, like $P_{10-mistakes}$. We could use this to solve for $P$. However, if we did not have a large enough data set, we might get a different value of $P$ if we substituted in $P_{15-mistakes}$. In this scenario, we could find a $P$ value which creates $P_{k-mistakes}$ that are closest to the experimental $P_{k-mistakes}$ values we have (using some metric, like minimizing error).\n",
    "\n",
    "The question of finding the probability of specific mistake is more complicated. The reason being, it is difficult to determine if a specific mistake happened and not another. If we had a string CGT and another string CAT, we can't simply say that there was a mutation. It could be that mutations are acutally incredibly unlikely, and instead deletion and insertion create many of the signs we think come from mutations. Thus, with this dataset, the options for determining the probability for individual types of mistakes are limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Algorithm\n",
    "\n",
    "While with this example, we were able to manually examine the strings and determine which lineage was the most likely. However, this would not be possible with longer strings or more strings. Instead, we should devise a general algorithm that tells us the most likely lineage. What we will do is run a parameter sweep of all possible lineages, and determine which is optimal (this is a brute force approach).\n",
    "\n",
    "With this algorithim, I will assume that there is a complete tree, i.e. that the number of nodes n = 2^g for some g. It returns the mininum possible changes and the associated tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum number of total changes for any lineage is 98\n",
      "This is achieved with the grandfather as node 0\n",
      "with children  1 and 6\n",
      "whose children are 2 3\n",
      "and  4 5 , respectively.\n"
     ]
    }
   ],
   "source": [
    "def tree_checker(tree, min_changes):\n",
    "    \"\"\"\n",
    "    tree - is a tuple of the strings in the specific tree order.\n",
    "        for example if lis = (0,1,2,3,4,5,6),\n",
    "        the grandparent is 0 with children 1 and 2, \n",
    "        1's children are 3 and 4 and 2's children are 5 and 6\n",
    "        \n",
    "    min_changes - this is the min_changes array we got in the last section\n",
    "    \n",
    "    \"\"\"\n",
    "    gen = math.log(len(tree),2)\n",
    "    answer = 0\n",
    "    index = 0\n",
    "    for i in range(2**(int(gen))-1):\n",
    "        for _ in range(2):\n",
    "            index +=1\n",
    "            answer += min_changes[tree[i]][tree[index]]\n",
    "    return answer\n",
    "                \n",
    "\n",
    "answer_key = []\n",
    "parameter_sweep = list(itertools.permutations(range(7)))\n",
    "for parameter in parameter_sweep:\n",
    "    answer_key.append(tree_checker(parameter, min_changes))\n",
    "\n",
    "min_val = min(answer_key)\n",
    "answer_key = np.array(answer_key)\n",
    "indexies = np.where(answer_key == min_val)\n",
    "print (\"The minimum number of total changes for any lineage is\", min_val)\n",
    "print (\"This is achieved with the grandfather as string\", parameter_sweep[indexies[0][0]][0])\n",
    "print (\"with children \", parameter_sweep[indexies[0][0]][1], 'and', parameter_sweep[indexies[0][0]][2])\n",
    "print (\"whose children are\",parameter_sweep[indexies[0][0]][3] ,parameter_sweep[indexies[0][0]][4])\n",
    "print ('and ',parameter_sweep[indexies[0][0]][5] ,parameter_sweep[indexies[0][0]][6], \", respectively.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave us the same answer as what we got when we manually checked the strings. This algorithm will give us the correct answer every single time, as it checks all possible parameters. It is useful in this sense, as we know it will always be correct. However, as we will soon see, with large sets of genes, it would take a prohibitively long amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity\n",
    "\n",
    "We now must examine the complexity of our algorithm. We will define M as the length of a gene (while not all genes are the same, they are similar), and N as the number of genes. We first note that the complexity of our LCS algorithm is O(M^2), as it creates a table with width and length proportional to the length of a gene. We then do this N^2 times, as we must compute the LCS for each pair of strings. Thus, getting our minimum_changes array is O(M^2 N^2). We must now find the complexity of our tree checker parameter sweep. This operation is O(N!). \n",
    "\n",
    "This complexity is quite bad, as with any large number of genes, this would be impossible to compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy \n",
    "\n",
    "As the time complexity of our brute force algorithm did not scale well, I created a greedy algorithm that attempts to solve the problem. Note that this algorithm is not guaranteed to find the optimal solution. \n",
    "\n",
    "The first thing to do is to find the root node. In my algorithm, I found the node that is most similar to all other nodes (least changes to get to all other nodes). With this done, the next step is to find the children. Note that my specific algorithm does not take advantage of any optimal substructure. With each parent, I find the children using a greedy approach. It was initially appealing to have a recursive function, where after a child is found, and its children need to be found, a recursive function is called to solve a similar subproblem. The only problem with this is that the available strings (strings not already in the tree) are very important, and as such the order of solving problems matters. I chose to have two greedy choices for each parent (the strings with the lowest minimum changes). Each of these strings is added to a `waiting_for_kids` list and taken of of the `available` list. When there are no more strings to add the process is done. The greedy aspect of this algorithm is choosing children, as the locally optimal choice is always made, despite the future consequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 6, 0, 4, 5]\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def greedy(min_changes):\n",
    "    #find the column with the most similarity\n",
    "    root = min_changes.sum(axis=0).argmin()\n",
    "    \n",
    "    #create the lists\n",
    "    tree = [root]\n",
    "    waiting_for_kids = [root]\n",
    "    available = list(range(len(min_changes)))\n",
    "    available.remove(root)\n",
    "    \n",
    "    while available:\n",
    "        active = waiting_for_kids.pop(0)\n",
    "        \n",
    "        #find child one\n",
    "        child1 = choose_children(min_changes, active, available)\n",
    "        available.remove(child1)\n",
    "        tree.append(child1)\n",
    "        waiting_for_kids.append(child1)\n",
    "        \n",
    "        #find child two\n",
    "        child2 = choose_children(min_changes, active, available)\n",
    "        available.remove(child2)\n",
    "        tree.append(child2)\n",
    "        waiting_for_kids.append(child2)\n",
    "    return tree\n",
    "    \n",
    "\n",
    "    #this function is greedy, choosing the child with the lowest minimum changes\n",
    "def choose_children(min_changes, active, available):\n",
    "    lis = []\n",
    "    counter = -1\n",
    "    for i in available:\n",
    "        counter +=1\n",
    "        lis.append(min_changes[active][i])\n",
    "        if lis[counter] == min(lis):\n",
    "            index = i\n",
    "    return index\n",
    "        \n",
    "#choose_children(min_changes, 1, available)\n",
    "\n",
    "sol = greedy(min_changes)\n",
    "print (sol)\n",
    "print (tree_checker(sol, min_changes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, this algorithm does not achieve the optimal solution. We do, however, get a better running time. An upper bound time complexity of this algorithm is O(N^2). However, in order to get our `min_changes`, we have an O(M^2 N^2) algorithm. This absorbs the O(N^2), and our overall running time for computing the lineage is O(M^2 N^2).\n",
    "\n",
    "The first problem it has is choosing the root node, as it chooses the incorrect node. Secondly, the greedy aspect, while increasing speed, also leads to suboptimal solutions. With real genome sequencing, we have a large interest in being correct, and thus we would need to find a better algorithm.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
